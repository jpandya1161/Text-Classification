# Text-Classification
Here we are given a Text dataset which contains Ham and Spam emails. Now we must make different classifier models to evaluate that on getting a new dataset, machine should be able to decide if that email is ham or spam. Also, we are comparing evaluation metrics for different models for the same problem, given different new datasets.

# Steps to run the Project
---------------------------
-> Given project1_datasets zip file, to run the code, just have to upload zip file in fileas on Colab. 
-> After that all the code is working on its own and printing Accuracy for all the dataset and respective classifier model.
-> Also at last, Evaluation metrics and their respective accuracy_score, precision_score, recall_score, f1_score for all three datasets (enron1, enron2, enron4), to compare and to get an understanding how all the models are working.

# All classifier model and dataset
-----------------------------------------------
1) Multinomial Naive Bayes (Full Bag of Words test data)
2) Discrete Naive Bayes (Full Bernoulli test data)
3) Logistic Regression (Full Bag of Words test data)
4) Logistic Regression (Full Bernoulli test data)
5) SGD Classifier (Full Bag of Words test data)
6) SGD Classifier (Full Bernoulli test data)

7) Multinomial Naive Bayes (Enron1, Enron2, Enron4 Bag of Words test data)
8) Discrete Naive Bayes (Enron1, Enron2, Enron4 Bernoulli test data)
9) Logistic Regression (Enron1, Enron2, Enron4 Bag of Words test data)
10) Logistic Regression (Enron1, Enron2, Enron4 Bernoulli test data)
11) SGD Classifier (Enron1, Enron2, Enron4 Bag of Words test data) 
12) SGD Classifier (Enron1, Enron2, Enron4 Bernoulli test data)
